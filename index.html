<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Qingyang Zhang</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="images/zqy.jpg">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Qingyang Zhang 张庆阳</name>
              </p>
                <p>
                I am a 2nd-year PhD student at Tianjin University, supervised by <a href="http://cic.tju.edu.cn/faculty/zhangchangqing/index.html">Prof. Changqing Zhang</a>. Currently, I am at an internship at Shanghai AI lab, co-supervised by Dr. Ganqu Cui.
                </p>
		<p>
		I received my Bachelor's degree in School of Computer Science from Tianjin University. After that, I pursued my Master's in the School of Computer Science at Tianjin University and transitioned into a PhD candidate through the direct doctoral program (2+4) in 2024. I also had a wonderful time at Tencent AI Lab from 2024.04-2025.06, mentored by <a herf="https://yataobian.com">Dr. Yatao Bian</a> and <a herf="https://peilinzhao.github.io">Dr. Peilin Zhao</a>.
                </p>
		<p>
                My research interests include Large Reasoning Models, Out-of-Distribution Detection/Generalization and Multimodal Learning.   
                <p style="text-align:center">
                  <a href="mailto:qingyangzhang@tju.edu.cn">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=64vwsrsAAAAJ">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/QingyangZhang">Github</a>&nbsp;/&nbsp;
                  <a href="data/CV-CN.pdf">中文简历</a> &nbsp;/&nbsp;
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/zqy.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/zqy.jpg" class="hoverZoomLink"></a>
              </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
	     	<p>
              <strong>[2025-09]</strong> One paper about Unsupervised LLM Reasoning Incentivization has been accepted by NeurIPS as a Spotlight.
            </p>
	     	<p>
              <strong>[2025-06]</strong> Gave a talk about "Reinforcement Learning with Internal Reward" @ Huawei 2012 Lab. Thanks Dr. Xueyan Niu's invitation!
            </p>
	     	<p>
              <strong>[2025-06]</strong> Starting an internship at Shanghai AI lab, mentored by Dr. Ganqu Cui.
            </p>
            <p>
              <strong>[2025-01]</strong> One paper about test-time adaption has been accepted by ICLR.
            </p>
            <p>
              <strong>[2024-05]</strong> One paper about Out-of-distribution Detection has been accepted by NeurIPS.
            </p>
            <p>
              <strong>[2024-05]</strong> We release a survey about fusion of low-quality multi-modal data. <a href="https://arxiv.org/abs/2404.18947">[arXiv]</a>
            </p>
            <p>
              <strong>[2024-04]</strong> Starting an internship at Tencent AI Lab, mentored by Dr. Yatao Bian.
            </p>
            <p>
              <strong>[2023-04]</strong> Two paper accepted by ICML including one Oral paper, thanks to all co-authors.
            </p>
          </td>
        </tr>
      </tbody></table>

    <br>
    
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <heading style="padding:20px">Publications</heading>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/EMPO.png" alt="clean-usnob" width="320" height="160">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Right Question is Already Half the Answer: Fully Unsupervised LLM Reasoning Incentivization</papertitle>
              <br>
              <br>
              <strong>Qingyang Zhang</strong>, Haitao Wu, Changqing Zhang, Peilin Zhao, Yatao Bian
              <br>
			  <br>
              <em>NeurIPS <strong>Spotlight</strong></em>, 2025
              <br>
			  <br>
              <a href="https://arxiv.org/abs/2504.05812">arXiv</a> / <a href="https://github.com/QingyangZhang/EMPO"> code </a>
              </a>
              <br>
              <br>
              <p>Incentivizate LLM's reasoning capability without any external supervision (human-verified reasoning trace, golden answer or pretrained reward model).</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/COME-poster.png" alt="clean-usnob" width="320" height="160">
            </td>
            <td width="75%" valign="middle">
              <papertitle>COME: Test-time Adaption by Conservatively Minimizing Entropy </papertitle>
              <br>
              <br>
              <strong>Qingyang Zhang</strong>, Yatao Bian, Xinke Kong, Peilin Zhao and Changqing Zhang
              <br>
              <br>
              <em>ICLR</em>, 2025
              <br>
			  <br>
              <a href="https://openreview.net/pdf?id=506BjJ1ziZ">arXiv</a> / <a href="hhttps://github.com/BlueWhaleLab/COME">code
              </a>
              <br>
              <br>
              <p>A simple learning principle for test time adaption.</p>
            </td>
          </tr>
            
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DUL-poster.png" alt="clean-usnob" width="320" height="160">
            </td>
            <td width="75%" valign="middle">
              <papertitle>The Best of both Worlds: On the Dilemma of Out-of-Distribution Detection </papertitle>
              <br>
              <br>
              <strong>Qingyang Zhang</strong>, Qiuxuan Feng, Joey Tianyi Zhou, Yatao Bian, Qinghua Hu and Changqing Zhang
              <br>
			  <br>
              <em>NeurIPS</em>, 2024
              <br>
			  <br>
              <a href="https://arxiv.org/pdf/2410.11576">arXiv</a> / <a href="https://github.com/QingyangZhang/DUL">code
              </a>
              <br>
              <br>
              <p>Solve conflicts between OOD detection and generalization for dual-optimal performance.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/qmf.jpg" alt="clean-usnob" width="320" height="160">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Provable Dynamic Fusion for Low-quality Multimodal Learning</papertitle>
              <br>
              <br>
              <strong>Qingyang Zhang</strong>, Haitao Wu, Changqing Zhang, Qinghua Hu, Huazhu Fu, Joey Tianyi Zhou, Xi Peng
              <br>
              <br>
              <em>ICML</em>, 2023
              <br>
              <a href="https://proceedings.mlr.press/v202/zhang23ar/zhang23ar.pdf">arXiv</a> / <a href="https://github.com/QingyangZhang/QMF">code
              </a>
              <br>
              <p>Theory-inspired dynimical fuse strategy for quality-varying modalities in real world.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cml.jpg" alt="clean-usnob" width="320" height="160">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Calibrating Multimodal Learning</papertitle>
              <br>
              <br>
              Huan Ma, <strong>Qingyang Zhang (co-first author)</strong>, Changqing Zhang, Bingzhe Wu, Huazhu Fu, Joey Tianyi Zhou, Qinghua Hu
              <br>
              <br>
              <em>ICML <strong>Oral</strong></em>, 2023
              <br>
              <a href="https://proceedings.mlr.press/v202/ma23i/ma23i.pdf">arXiv</a> / <a href="https://github.com/QingyangZhang/CML">code
              </a>
              <br>
              <p>Mitigate the greedy nature of multimodal learning by regularizing the model confidence.</p>
            </td>
          </tr>

        </tbody></table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
      <heading style="padding:20px">Survey</heading>
      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="images/low_quality.jpg" alt="clean-usnob" width="320" height="160">
        </td>
        <td width="75%" valign="middle">
          <papertitle>Multimodal Fusion on Low-quality Data: A Comprehensive Survey</papertitle>
          <br>
          <br>
          <strong>Qingyang Zhang</strong>, Yake Wei, Zongbo Han, Huazhu Fu, Xi Peng, Cheng Deng, Qinghua Hu, Cai Xu, Jie Wen, <a href="https://dtaoo.github.io">Di Hu</a>, Changqing Zhang
          <br>
          <br>

          <br>
          <a href="https://arxiv.org/abs/2404.18947">arXiv</a> / <a href="https://github.com/QingyangZhang/awesome-low-quality-multimodal-learning">awesome list</a> 
          <br>
          <p>A systematical survey about fusion of low-quality multi-modal data.</p>
        </td>
      </tr>

    </tbody></table>

    <br>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Services</heading>
          <p>
            <strong>Conference Reviewer:</strong> ICLR 2022-2024, NeurIPS 2023-2024, ICML 2024
          </p>
        </td>
      </tr>
    </tbody></table>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Awards</heading>
          <p>
            <strong>National Scholarship (twice, 1%)</strong> 2022, 2023
          </p>
        </td>
      </tr>
    </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <p font-size:small;>
                <br>
                <br>
                <div style="float:left;">
                    Last updated at Apr. 2025
                </div>
                <div style="float:right;">
                    Thanks <a href="https://jonbarron.info">Jon Barron</a> for this amazing template.
                </div>
                <br>
                <br>        
            </p>                           
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
